<h1>Precomputed Tags: Replacing Dynamic Search with Pre-computed Indexes</h1>

<p>When designing the tag system for VibeBlog, I encountered a key question: <strong>How to implement high-performance tag-based browsing without using a database?</strong></p>

<p>The traditional CMS approach is to dynamically scan all posts on each request, then filter posts matching the tag using a for-loop. However, this approach has several problems:</p>

<ul>
<li>❌ Every request requires scanning the entire content folder</li>
<li>❌ Requires dynamic computation, unable to fully leverage SSG advantages</li>
<li>❌ Performance degrades linearly as the number of posts increases</li>
<li>❌ Not suitable for CDN caching</li>
</ul>

<p>Therefore, I chose the <strong>Precomputed Tags</strong> architecture.</p>

<h2>What are Precomputed Tags?</h2>

<p>The core concept of Precomputed Tags is: <strong>Calculate all classification relationships at build time, store them as static JSON files, and the frontend only needs to read them with zero computation.</strong></p>

<p>It's like a library's index card system:</p>

<ul>
<li>Traditional way: Every time someone asks "What books are about LLM?", the librarian has to search through the entire library</li>
<li>Precomputed way: The library has already prepared index cards, just flip to the "LLM" page, which lists all relevant book numbers</li>
</ul>

<h2>Data Structure Design</h2>

<h3>1. Post Metadata (One JSON per post)</h3>

<p>Each post has a corresponding JSON file in the <code>content/meta/</code> directory:</p>

<pre><code>content/meta/how-i-use-vllm.json
{
  "slug": "how-i-use-vllm",
  "title": "How I Use vLLM to Run 7B Models Locally",
  "date": "2025-12-02",
  "tags": ["LLM", "vLLM", "Local Deployment", "Experiment Notes"],
  "summary": "Recording my process of running vLLM on a single GPU at home.",
  "heroImage": "/images/2025-12-02-vllm-hero.png"
}
</code></pre>

<p>Tags are stored in the <code>tags</code> array here.</p>

<h3>2. Pre-computed Tag Index (tags.json)</h3>

<p>In <code>content/indexes/tags.json</code>, we pre-build a mapping of "tag → post slug list":</p>

<pre><code>content/indexes/tags.json
{
  "LLM": ["how-i-use-vllm", "llm-metrics", "runtime-benchmark"],
  "SvelteKit": ["vibeblog-infra", "routing-idea"],
  "AI-Blogging": ["ai-html-pipeline", "meta-generator"]
}
</code></pre>

<p>This file is automatically generated by a script before build, requiring no manual maintenance.</p>

<h2>Implementation</h2>

<h3>Script to Generate tags.json</h3>

<p>I wrote a simple Node.js script to scan all meta JSON files and automatically generate the index:</p>

<pre><code>scripts/generate-tags-index.ts

// Scan all meta files
for (const file of jsonFiles) {
  const meta = JSON.parse(fs.readFileSync(filePath, 'utf-8'));
  
  // Add post slug to corresponding tag
  for (const tag of meta.tags) {
    if (!tagsIndex[tag]) {
      tagsIndex[tag] = [];
    }
    tagsIndex[tag].push(meta.slug);
  }
}

// Write tags.json
fs.writeFileSync('content/indexes/tags.json', 
  JSON.stringify(tagsIndex, null, 2));
</code></pre>

<p>Run <code>npm run generate:tags</code> to update the index.</p>

<h3>SvelteKit Side: Read Only, No Computation</h3>

<p>In SvelteKit's server load function, we only need to read the pre-computed JSON:</p>

<pre><code>// src/routes/tags/[tag]/+page.server.ts
import { getTagsIndex, getPostMeta } from '$lib/content';

export const load = ({ params }) => {
  const tagsIndex = getTagsIndex(); // Read pre-computed JSON
  const slugs = tagsIndex[params.tag] || [];
  
  // Only read needed post metas, no need to scan all
  const posts = slugs.map(slug => getPostMeta(slug));
  
  return { tag: params.tag, posts };
};
</code></pre>

<p>Completely zero dynamic computation, pure data lookup (O(1)).</p>

<h2>Perfect Integration with AI Pipeline</h2>

<p>This architecture is particularly suitable for AI-automated content production workflows:</p>

<pre><code>raw post 
  → AI processing 
    → processed HTML (AI-formatted HTML)
    → meta JSON (AI-generated metadata, including tags)
      → Run generate:tags script
        → tags.json automatically updated
          → build → deploy
</code></pre>

<p>When AI generates a post, it can simultaneously:</p>

<ul>
<li>Analyze post content and automatically generate relevant tags</li>
<li>Generate meta JSON (including tags array)</li>
<li>Generate processed HTML</li>
</ul>

<p>Then run <code>npm run generate:tags</code> once, and all classification indexes are automatically updated.</p>

<h2>Advantages Summary</h2>

<h3>✅ Extremely High Performance</h3>

<ul>
<li>All classifications completed at build time</li>
<li>Frontend only reads JSON, zero computation</li>
<li>Perfect match with SSG + CDN</li>
</ul>

<h3>✅ Fully Version Controllable</h3>

<ul>
<li>Classifications are files, commits show changes</li>
<li>All content is files, easy to track</li>
</ul>

<h3>✅ Suitable for Large Numbers of Posts</h3>

<ul>
<li>Hundreds or thousands of posts make no difference</li>
<li>Query complexity is O(1), won't slow down as post count increases</li>
</ul>

<h3>✅ Suitable for AI Automation</h3>

<ul>
<li>AI directly outputs classification data structures</li>
<li>No need for complex database schemas</li>
<li>All logic runs before build</li>
</ul>

<h3>✅ Perfect Match with "AI-Generated Posts" Concept</h3>

<ul>
<li>AI determines tags when generating posts</li>
<li>Automatically updates tags.json</li>
<li>Fully automated content management workflow</li>
</ul>

<h2>Practical Applications</h2>

<p>In VibeBlog, this architecture implements:</p>

<ul>
<li><code>/tags</code> - All tags overview (read from tags.json)</li>
<li><code>/tags/LLM</code> - All LLM-related posts (O(1) query)</li>
<li>Post list page displays tags (read from meta JSON)</li>
<li>Post detail page displays tags (clickable to jump to tag page)</li>
</ul>

<p>All these features are <strong>zero runtime computation, pure static data</strong>.</p>

<h2>Extensibility</h2>

<p>This pattern can easily extend to other classification methods:</p>

<ul>
<li><code>content/indexes/years.json</code> - Classify by year</li>
<li><code>content/indexes/categories.json</code> - Classify by category</li>
<li><code>content/indexes/authors.json</code> - Classify by author</li>
</ul>

<p>Just generate the corresponding index file before build, and SvelteKit can use it directly.</p>

<h2>Conclusion</h2>

<p>The Precomputed Tags architecture proves that: <strong>You don't need a database, you don't need dynamic queries, you can implement a high-performance tag system using files + pre-computation.</strong></p>

<p>This method is particularly suitable for:</p>

<ul>
<li>Static Site Generation (SSG)</li>
<li>AI-automated content production</li>
<li>Version-controlled content management</li>
<li>Blog systems pursuing ultimate performance</li>
</ul>

<p>In VibeBlog's implementation, this architecture not only solves the tag classification problem but also becomes the foundation of the entire AI-First content management system.</p>

<p>If you're building a similar system, try the Precomputed Tags architecture. You'll find it simpler, faster, and more controllable than traditional dynamic search approaches.</p>

