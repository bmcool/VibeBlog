<h1>自動化找回 1000+ 軟體官方網站：一個智能搜索腳本的設計邏輯</h1>
<h2>背景：從人工維護到自動化的挑戰</h2>

<p>有一間軟體經銷商，原本是靠人工在維護網站上所有的產品。面對 1000 多個軟體，每個軟體的網站結構都不一樣，如果一路以來都寫好爬蟲，這水到渠成，但一個爬蟲都沒有的情況下，要一蹴可及，也並非簡單的事情。</p>
<p>從一開始例如 Cursor 這類的 agent，配合 Playwright MCP 來做，發現雖然做得到，但效率極差，且成本高昂，甚至準確度也無法放心的大量跑。中間也換過好幾次做法，在 1000 多檔軟體的各種例外狀況下（官網早失聯、產品變成子產品、換了網址...etc），其實還是應該要按部就班的來做。</p>
<p><strong>第一件事情就是先找回這些軟體的官方網站。</strong> 這就是 <code>openai_web_search.py</code> 腳本的使命。</p>
<h2>腳本整體架構</h2>
<p>這個腳本的核心目標是：<strong>自動化地從產品名稱找到對應的官方網站域名</strong>。整個系統分為三個主要層次：</p>
<ol>
<li><strong>WebSearchTool</strong>：底層的網絡搜索工具，負責實際的搜索和網頁抓取</li>
<li><strong>OpenAISearchAssistant</strong>：中層的 AI 助手，負責優化搜索策略和判斷結果</li>
<li><strong>主函數流程</strong>：頂層的批量處理邏輯，負責從數據庫讀取產品並批量處理</li>
</ol>
<h2>核心組件一：WebSearchTool 類</h2>
<h3>搜索基礎設施</h3>
<p><code>WebSearchTool</code> 使用 <code>crawl4ai</code> 作為底層爬蟲引擎，配置如下：</p>
<div class="codehilite"><pre><span></span><code><span class="bp">self</span><span class="o">.</span><span class="n">browser_config</span> <span class="o">=</span> <span class="n">BrowserConfig</span><span class="p">(</span>
    <span class="n">headless</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">run_config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
    <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="o">.</span><span class="n">BYPASS</span><span class="p">,</span>
    <span class="n">delay_before_return_html</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>  <span class="c1"># 等待 2 秒讓頁面載入</span>
    <span class="n">wait_for_images</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">screenshot</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>選擇 <code>crawl4ai</code> 而非傳統的 <code>requests</code> 是因為：<br />
- 可以處理 JavaScript 渲染的頁面<br />
- 更好的反爬蟲對抗能力<br />
- 支持異步操作，提高效率</p>
<h3>搜索執行邏輯</h3>
<p><code>_search_with_language</code> 方法的核心流程：</p>
<ol>
<li>
<p><strong>構建搜索 URL</strong>：使用 DuckDuckGo 的 HTML 搜索接口<br />
<code>python
   search_url = f"https://html.duckduckgo.com/html/?q={urllib.parse.quote(query)}"</code></p>
</li>
<li>
<p><strong>重試機制</strong>：最多重試 3 次，每次重試前等待時間遞增（10秒、20秒、30秒）</p>
</li>
<li>特別處理 403 錯誤（速率限制）</li>
<li>
<p>其他錯誤也會重試，但會記錄並繼續</p>
</li>
<li>
<p><strong>解析搜索結果</strong>：從 HTML 中提取標題、URL 和摘要</p>
</li>
<li>處理 DuckDuckGo 的重定向 URL（<code>/l/?uddg=...</code> 格式）</li>
<li>提取真實的目標 URL</li>
</ol>
<h3>簡單的官方域名查找</h3>
<p><code>find_official_domain</code> 方法使用基於分數的匹配算法：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 計算匹配分數</span>
<span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># 域名中包含產品名稱（不區分大小寫）- 最高優先級</span>
<span class="k">if</span> <span class="n">product_name_clean</span> <span class="ow">in</span> <span class="n">domain_lower</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="mi">10</span>  <span class="c1"># 域名匹配是最重要的指標</span>

<span class="c1"># 標題中包含產品名稱</span>
<span class="k">if</span> <span class="n">product_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">title</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="mi">5</span>

<span class="c1"># 標題中包含 &quot;official&quot;</span>
<span class="k">if</span> <span class="s1">&#39;official&#39;</span> <span class="ow">in</span> <span class="n">title</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="mi">3</span>

<span class="c1"># 摘要中包含產品名稱</span>
<span class="k">if</span> <span class="n">product_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">snippet</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="mi">2</span>

<span class="c1"># 常見的官方域名模式（.com 優先）</span>
<span class="k">if</span> <span class="s1">&#39;.com&#39;</span> <span class="ow">in</span> <span class="n">domain</span><span class="p">:</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="mi">2</span>
</code></pre></div>

<p>這個方法簡單直接，但準確度有限，因為：<br />
- 無法區分官方網站和第三方網站<br />
- 無法處理產品名稱模糊的情況<br />
- 無法理解產品描述來輔助判斷</p>
<h2>核心組件二：優化的官方域名查找</h2>
<h3>為什麼需要優化？</h3>
<p>簡單的基於分數的匹配在實際應用中遇到很多問題：<br />
- 產品名稱可能有多種表達方式（如 "Adobe Photoshop" vs "Photoshop"）<br />
- 第三方網站可能包含產品名稱但並非官方網站<br />
- 產品可能已經改名或合併到其他產品線</p>
<p>因此，我們需要引入 <strong>LLM 來進行智能判斷</strong>。</p>
<h3>優化流程的三個階段</h3>
<h4>階段一：提取搜索關鍵詞</h4>
<p><code>extract_product_search_keywords</code> 方法使用 LLM 將產品名稱轉換為 1-3 個最有效的搜索關鍵詞：</p>
<div class="codehilite"><pre><span></span><code><span class="n">extraction_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;請為以下產品名稱提取1-3個英文搜索關鍵詞，這些關鍵詞應該是最容易搜尋到官方網站的名稱。</span>

<span class="s2">要求：</span>
<span class="s2">1. 如果是中文產品名，先翻譯成官方英文名稱</span>
<span class="s2">2. 提取1-3個關鍵詞組合，優先級從高到低：</span>
<span class="s2">   - 公司名 + 產品名（如 &quot;adobe photoshop&quot;）</span>
<span class="s2">   - 公司名（如 &quot;adobe&quot;）</span>
<span class="s2">   - 產品名（如 &quot;photoshop&quot;）</span>
<span class="s2">3. 只使用官方英文名稱，不要使用常見單字</span>
</code></pre></div>

<p>這個階段的關鍵是：<strong>找到最容易搜到官網的關鍵詞組合</strong>，而不是最完整的產品名稱。</p>
<h4>階段二：順序搜索並批量判斷</h4>
<p><code>find_official_domain_optimized</code> 方法的核心邏輯：</p>
<ol>
<li>
<p><strong>順序搜索關鍵詞</strong>：按優先級順序搜索每個關鍵詞<br />
<code>python
   for keyword_idx, keyword in enumerate(search_keywords, 1):
       results = await self.search(keyword, num_results=num_results_per_keyword)</code></p>
</li>
<li>
<p><strong>提取候選域名</strong>：從搜索結果中提取所有可能的域名</p>
</li>
<li>處理 DuckDuckGo 重定向 URL</li>
<li>
<p>跨關鍵詞去重（同一個域名只保留一次）</p>
</li>
<li>
<p><strong>批量 LLM 判斷</strong>：一次性將所有候選域名提交給 LLM 判斷<br />
   ```python<br />
   async def judge_candidates(candidates: List[Dict[str, str]]) -&gt; List[Dict[str, Any]]:<br />
       judgment_prompt = f"""請判斷以下多個網站是否為產品 "{product_name}" 的官方網站。</p>
<p>請仔細分析每個網站，判斷是否為該產品的官方網站。請考慮：<br />
   1. 域名是否與產品名稱相關<br />
   2. 標題和摘要是否與產品名稱和描述匹配<br />
   3. 是否看起來像官方網站（而非第三方網站、新聞網站、字典網站等）</p>
<p>請以 JSON 格式返回一個數組，每個元素對應一個網站的判斷結果：<br />
   [<br />
       {{<br />
           "domain": "域名1",<br />
           "is_official": true/false,<br />
           "confidence": 0.0-1.0,<br />
           "reason": "判斷理由"<br />
       }},<br />
       ...<br />
   ]<br />
   """<br />
   ```</p>
</li>
<li>
<p><strong>早期終止策略</strong>：如果找到信心度 &gt; 0.9 的官方域名，立即返回，跳過剩餘關鍵詞<br />
<code>python
   if best_domain and best_confidence &gt; 0.9:
       print(f"✅ 找到高信心度官方域名: {best_domain}")
       return best_domain</code></p>
</li>
</ol>
<h3>批量判斷的優勢</h3>
<p>為什麼要批量判斷而不是逐個判斷？</p>
<ol>
<li><strong>成本效率</strong>：一次 API 調用可以判斷多個候選域名，比逐個調用更節省成本</li>
<li><strong>上下文一致性</strong>：LLM 可以同時比較多個候選域名，做出更準確的判斷</li>
<li><strong>速度提升</strong>：減少 API 調用次數，提高整體處理速度</li>
</ol>
<h3>錯誤處理和速率限制</h3>
<p>腳本實現了完善的錯誤處理機制：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 如果遇到 403 錯誤，等待更長時間（30-60秒）</span>
<span class="k">if</span> <span class="s2">&quot;403&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span> <span class="ow">or</span> <span class="s2">&quot;Forbidden&quot;</span> <span class="ow">in</span> <span class="n">error_msg</span><span class="p">:</span>
    <span class="n">delay</span> <span class="o">=</span> <span class="mi">30</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>  <span class="c1"># 30-60 秒隨機延遲</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">keyword</span> <span class="o">!=</span> <span class="n">search_keywords</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="c1"># 其他錯誤也添加延遲（15-20秒）</span>
    <span class="n">delay</span> <span class="o">=</span> <span class="mi">15</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>
</code></pre></div>

<p>關鍵設計點：<br />
- <strong>隨機延遲</strong>：避免被識別為機器人行為<br />
- <strong>分級延遲</strong>：403 錯誤等待更長時間<br />
- <strong>繼續執行</strong>：即使某個關鍵詞失敗，也會繼續處理下一個</p>
<h2>核心組件三：主函數批量處理流程</h2>
<h3>產品過濾策略</h3>
<p><code>main_async</code> 函數實現了智能的產品過濾邏輯：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 默認行為：跳過已有 URL 的產品，以及1天內已處理過的產品</span>
<span class="c1"># 但優先處理：沒有網址但有時間戳的（代表抓取失敗的）</span>
<span class="n">failed_products</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 沒有網址但有時間戳的產品（優先處理）</span>
<span class="n">new_products</span> <span class="o">=</span> <span class="p">[]</span>     <span class="c1"># 完全沒有記錄的產品</span>

<span class="k">for</span> <span class="n">product_id</span> <span class="ow">in</span> <span class="n">all_product_ids</span><span class="p">[:</span><span class="n">args</span><span class="o">.</span><span class="n">limit</span> <span class="o">*</span> <span class="mi">3</span><span class="p">]:</span>
    <span class="n">url_info</span> <span class="o">=</span> <span class="n">get_product_url_with_timestamp</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">product_id</span><span class="p">)</span>

    <span class="c1"># 如果有 URL，跳過</span>
    <span class="k">if</span> <span class="n">url_info</span> <span class="ow">and</span> <span class="n">url_info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">):</span>
        <span class="n">skip_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">continue</span>

    <span class="c1"># 如果1天內已處理過，跳過（除非是失敗的）</span>
    <span class="k">if</span> <span class="n">url_info</span> <span class="ow">and</span> <span class="n">url_info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;last_fetched_at&#39;</span><span class="p">):</span>
        <span class="n">last_fetched</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">fromisoformat</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">last_fetched</span><span class="o">.</span><span class="n">isoformat</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">one_day_ago</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">url_info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">):</span>
                <span class="n">failed_products</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">product_id</span><span class="p">)</span>  <span class="c1"># 優先處理失敗的</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">skip_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">continue</span>

    <span class="c1"># 分類處理</span>
    <span class="k">if</span> <span class="n">url_info</span> <span class="ow">and</span> <span class="n">url_info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;last_fetched_at&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">url_info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;url&#39;</span><span class="p">):</span>
        <span class="n">failed_products</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">product_id</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">url_info</span><span class="p">:</span>
        <span class="n">new_products</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">product_id</span><span class="p">)</span>

<span class="c1"># 優先處理失敗的產品，然後處理新產品</span>
<span class="n">product_ids_to_process</span> <span class="o">=</span> <span class="p">(</span><span class="n">failed_products</span> <span class="o">+</span> <span class="n">new_products</span><span class="p">)[:</span><span class="n">args</span><span class="o">.</span><span class="n">limit</span><span class="p">]</span>
</code></pre></div>

<p>這個策略的優勢：<br />
1. <strong>避免重複處理</strong>：已有 URL 的產品直接跳過<br />
2. <strong>優先重試失敗</strong>：之前失敗的產品優先處理<br />
3. <strong>時間窗口控制</strong>：1 天內已處理過的產品跳過（除非失敗）</p>
<h3>處理流程</h3>
<p>對每個產品的處理流程：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 1. 獲取產品信息</span>
<span class="n">product_data</span> <span class="o">=</span> <span class="n">get_latest_version</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">product_id</span><span class="p">)</span>
<span class="n">product_name</span> <span class="o">=</span> <span class="n">product_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">product_desc1</span> <span class="o">=</span> <span class="n">product_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;desc1&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;&#39;</span>

<span class="c1"># 2. 查找官方域名</span>
<span class="n">official_domain</span> <span class="o">=</span> <span class="k">await</span> <span class="n">find_official_domain_optimized</span><span class="p">(</span>
    <span class="n">product_name</span><span class="o">=</span><span class="n">product_name</span><span class="p">,</span>
    <span class="n">product_desc1</span><span class="o">=</span><span class="n">product_desc1</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">api_key</span>
<span class="p">)</span>

<span class="c1"># 3. 保存結果</span>
<span class="k">if</span> <span class="n">official_domain</span><span class="p">:</span>
    <span class="n">official_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://</span><span class="si">{</span><span class="n">official_domain</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">set_product_url</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">product_id</span><span class="p">,</span> <span class="n">official_url</span><span class="p">)</span>
    <span class="n">success_count</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># 未找到官方域名，清空現有網址但更新撷取時間</span>
    <span class="n">delete_product_url</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">product_id</span><span class="p">)</span>
    <span class="n">update_product_url_fetched_time</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">product_id</span><span class="p">)</span>
    <span class="n">cleared_count</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div>

<p>關鍵設計點：<br />
- <strong>即使失敗也更新時間戳</strong>：避免無限重試同一個產品<br />
- <strong>清空無效 URL</strong>：如果找不到官方域名，清空現有的錯誤 URL<br />
- <strong>統計信息</strong>：記錄成功、失敗、跳過的數量</p>
<h2>技術細節：URL 處理和域名提取</h2>
<h3>DuckDuckGo 重定向處理</h3>
<p>DuckDuckGo 使用重定向 URL 來保護用戶隱私，格式為 <code>/l/?uddg=...</code>。腳本需要提取真實的目標 URL：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 處理 DuckDuckGo 的重定向 URL</span>
<span class="k">if</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;//duckduckgo.com/l/&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;/l/?&#39;</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlparse</span><span class="p">(</span><span class="n">url</span> <span class="k">if</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;//&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;https:</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">parse_qs</span><span class="p">(</span><span class="n">parsed</span><span class="o">.</span><span class="n">query</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;uddg&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">real_url</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">unquote</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;uddg&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;⚠️  解析 URL 失敗: </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">, 錯誤: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">continue</span>
</code></pre></div>

<h3>域名提取邏輯</h3>
<p><code>_extract_domain_from_url</code> 方法處理各種 URL 格式：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">_extract_domain_from_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="c1"># 1. 處理 DuckDuckGo 重定向</span>
    <span class="k">if</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;//duckduckgo.com/l/&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;/l/?&#39;</span><span class="p">):</span>
        <span class="c1"># 提取 uddg 參數中的真實 URL</span>
        <span class="o">...</span>

    <span class="c1"># 2. 跳過 DuckDuckGo 的域名</span>
    <span class="k">if</span> <span class="s1">&#39;duckduckgo.com&#39;</span> <span class="ow">in</span> <span class="n">url</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># 3. 如果 URL 沒有協議，添加 https://</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s1">&#39;http://&#39;</span><span class="p">,</span> <span class="s1">&#39;https://&#39;</span><span class="p">)):</span>
        <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># 4. 解析域名</span>
    <span class="n">parsed</span> <span class="o">=</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">domain</span> <span class="o">=</span> <span class="n">parsed</span><span class="o">.</span><span class="n">netloc</span>

    <span class="c1"># 5. 移除 www. 前綴和端口號</span>
    <span class="k">if</span> <span class="n">domain</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;www.&#39;</span><span class="p">):</span>
        <span class="n">domain</span> <span class="o">=</span> <span class="n">domain</span><span class="p">[</span><span class="mi">4</span><span class="p">:]</span>
    <span class="k">if</span> <span class="s1">&#39;:&#39;</span> <span class="ow">in</span> <span class="n">domain</span><span class="p">:</span>
        <span class="n">domain</span> <span class="o">=</span> <span class="n">domain</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># 6. 驗證域名格式</span>
    <span class="k">if</span> <span class="s1">&#39;.&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">domain</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">domain</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">domain</span>
</code></pre></div>

<h2>實際應用效果</h2>
<p>這個腳本在實際應用中表現如何？</p>
<h3>優勢</h3>
<ol>
<li><strong>自動化程度高</strong>：可以批量處理大量產品，無需人工介入</li>
<li><strong>準確度提升</strong>：使用 LLM 判斷，比簡單的關鍵詞匹配更準確</li>
<li><strong>成本可控</strong>：批量判斷和早期終止策略降低了 API 調用成本</li>
<li><strong>錯誤恢復</strong>：完善的重試機制和錯誤處理</li>
</ol>
<h3>挑戰</h3>
<ol>
<li><strong>速率限制</strong>：DuckDuckGo 和目標網站可能限制爬蟲訪問</li>
<li><strong>特殊情況</strong>：產品改名、合併、官網失聯等情況需要人工處理</li>
<li><strong>成本</strong>：雖然有優化，但 LLM API 調用仍有成本</li>
</ol>
<h3>改進方向</h3>
<ol>
<li><strong>緩存機制</strong>：對已處理的產品進行緩存，避免重複處理</li>
<li><strong>並發控制</strong>：在遵守速率限制的前提下，提高並發處理能力</li>
<li><strong>結果驗證</strong>：定期驗證已保存的 URL 是否仍然有效</li>
</ol>
<h2>總結</h2>
<p><code>openai_web_search.py</code> 腳本展示了一個實用的自動化解決方案，它：</p>
<ol>
<li><strong>分層設計</strong>：將搜索、判斷、批量處理分離，各司其職</li>
<li><strong>智能判斷</strong>：使用 LLM 進行語義理解，而非簡單的關鍵詞匹配</li>
<li><strong>成本優化</strong>：批量處理和早期終止策略降低 API 成本</li>
<li><strong>錯誤處理</strong>：完善的重試機制和錯誤恢復策略</li>
<li><strong>實際可用</strong>：針對 1000+ 軟體的實際場景設計，處理各種邊緣情況</li>
</ol>
<p>這個腳本不僅解決了「找回官方網站」這個具體問題，更重要的是展示了如何在複雜的實際場景中，平衡自動化程度、準確度和成本。</p>
<hr />
<p><em>這篇文章詳細講述了自動化找回軟體官方網站的腳本設計邏輯，希望對正在構建類似自動化系統的開發者有所幫助。</em></p>